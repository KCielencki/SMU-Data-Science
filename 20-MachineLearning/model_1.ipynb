{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from scikitplot.metrics import plot_roc, plot_confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>koi_disposition</th>\n",
       "      <th>koi_fpflag_nt</th>\n",
       "      <th>koi_fpflag_ss</th>\n",
       "      <th>koi_fpflag_co</th>\n",
       "      <th>koi_fpflag_ec</th>\n",
       "      <th>koi_period</th>\n",
       "      <th>koi_period_err1</th>\n",
       "      <th>koi_period_err2</th>\n",
       "      <th>koi_time0bk</th>\n",
       "      <th>koi_time0bk_err1</th>\n",
       "      <th>...</th>\n",
       "      <th>koi_steff_err2</th>\n",
       "      <th>koi_slogg</th>\n",
       "      <th>koi_slogg_err1</th>\n",
       "      <th>koi_slogg_err2</th>\n",
       "      <th>koi_srad</th>\n",
       "      <th>koi_srad_err1</th>\n",
       "      <th>koi_srad_err2</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>koi_kepmag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54.418383</td>\n",
       "      <td>2.479000e-04</td>\n",
       "      <td>-2.479000e-04</td>\n",
       "      <td>162.513840</td>\n",
       "      <td>0.003520</td>\n",
       "      <td>...</td>\n",
       "      <td>-81</td>\n",
       "      <td>4.467</td>\n",
       "      <td>0.064</td>\n",
       "      <td>-0.096</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.105</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>291.93423</td>\n",
       "      <td>48.141651</td>\n",
       "      <td>15.347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19.899140</td>\n",
       "      <td>1.490000e-05</td>\n",
       "      <td>-1.490000e-05</td>\n",
       "      <td>175.850252</td>\n",
       "      <td>0.000581</td>\n",
       "      <td>...</td>\n",
       "      <td>-176</td>\n",
       "      <td>4.544</td>\n",
       "      <td>0.044</td>\n",
       "      <td>-0.176</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.233</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>297.00482</td>\n",
       "      <td>48.134129</td>\n",
       "      <td>15.436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.736952</td>\n",
       "      <td>2.630000e-07</td>\n",
       "      <td>-2.630000e-07</td>\n",
       "      <td>170.307565</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>...</td>\n",
       "      <td>-174</td>\n",
       "      <td>4.564</td>\n",
       "      <td>0.053</td>\n",
       "      <td>-0.168</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.201</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>285.53461</td>\n",
       "      <td>48.285210</td>\n",
       "      <td>15.597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.525592</td>\n",
       "      <td>3.760000e-06</td>\n",
       "      <td>-3.760000e-06</td>\n",
       "      <td>171.595550</td>\n",
       "      <td>0.001130</td>\n",
       "      <td>...</td>\n",
       "      <td>-211</td>\n",
       "      <td>4.438</td>\n",
       "      <td>0.070</td>\n",
       "      <td>-0.210</td>\n",
       "      <td>1.046</td>\n",
       "      <td>0.334</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>288.75488</td>\n",
       "      <td>48.226200</td>\n",
       "      <td>15.509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.134435</td>\n",
       "      <td>1.050000e-05</td>\n",
       "      <td>-1.050000e-05</td>\n",
       "      <td>172.979370</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>...</td>\n",
       "      <td>-232</td>\n",
       "      <td>4.486</td>\n",
       "      <td>0.054</td>\n",
       "      <td>-0.229</td>\n",
       "      <td>0.972</td>\n",
       "      <td>0.315</td>\n",
       "      <td>-0.105</td>\n",
       "      <td>296.28613</td>\n",
       "      <td>48.224670</td>\n",
       "      <td>15.714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  koi_disposition  koi_fpflag_nt  koi_fpflag_ss  koi_fpflag_co  koi_fpflag_ec  \\\n",
       "0       CONFIRMED              0              0              0              0   \n",
       "1  FALSE POSITIVE              0              1              0              0   \n",
       "2  FALSE POSITIVE              0              1              0              0   \n",
       "3       CONFIRMED              0              0              0              0   \n",
       "4       CONFIRMED              0              0              0              0   \n",
       "\n",
       "   koi_period  koi_period_err1  koi_period_err2  koi_time0bk  \\\n",
       "0   54.418383     2.479000e-04    -2.479000e-04   162.513840   \n",
       "1   19.899140     1.490000e-05    -1.490000e-05   175.850252   \n",
       "2    1.736952     2.630000e-07    -2.630000e-07   170.307565   \n",
       "3    2.525592     3.760000e-06    -3.760000e-06   171.595550   \n",
       "4    4.134435     1.050000e-05    -1.050000e-05   172.979370   \n",
       "\n",
       "   koi_time0bk_err1  ...  koi_steff_err2  koi_slogg  koi_slogg_err1  \\\n",
       "0          0.003520  ...             -81      4.467           0.064   \n",
       "1          0.000581  ...            -176      4.544           0.044   \n",
       "2          0.000115  ...            -174      4.564           0.053   \n",
       "3          0.001130  ...            -211      4.438           0.070   \n",
       "4          0.001900  ...            -232      4.486           0.054   \n",
       "\n",
       "   koi_slogg_err2  koi_srad  koi_srad_err1  koi_srad_err2         ra  \\\n",
       "0          -0.096     0.927          0.105         -0.061  291.93423   \n",
       "1          -0.176     0.868          0.233         -0.078  297.00482   \n",
       "2          -0.168     0.791          0.201         -0.067  285.53461   \n",
       "3          -0.210     1.046          0.334         -0.133  288.75488   \n",
       "4          -0.229     0.972          0.315         -0.105  296.28613   \n",
       "\n",
       "         dec  koi_kepmag  \n",
       "0  48.141651      15.347  \n",
       "1  48.134129      15.436  \n",
       "2  48.285210      15.597  \n",
       "3  48.226200      15.509  \n",
       "4  48.224670      15.714  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"exoplanet_data.csv\")\n",
    "# Drop the null columns where all values are null\n",
    "df = df.dropna(axis='columns', how='all')\n",
    "# Drop the null rows\n",
    "df = df.dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FALSE POSITIVE    3504\n",
       "CONFIRMED         1800\n",
       "CANDIDATE         1687\n",
       "Name: koi_disposition, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.koi_disposition.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>koi_fpflag_nt</th>\n",
       "      <th>koi_fpflag_ss</th>\n",
       "      <th>koi_fpflag_co</th>\n",
       "      <th>koi_fpflag_ec</th>\n",
       "      <th>koi_period</th>\n",
       "      <th>koi_period_err1</th>\n",
       "      <th>koi_period_err2</th>\n",
       "      <th>koi_time0bk</th>\n",
       "      <th>koi_time0bk_err1</th>\n",
       "      <th>koi_time0bk_err2</th>\n",
       "      <th>...</th>\n",
       "      <th>koi_slogg</th>\n",
       "      <th>koi_slogg_err1</th>\n",
       "      <th>koi_slogg_err2</th>\n",
       "      <th>koi_srad</th>\n",
       "      <th>koi_srad_err1</th>\n",
       "      <th>koi_srad_err2</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>koi_kepmag</th>\n",
       "      <th>koi_disposition_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54.418383</td>\n",
       "      <td>2.479000e-04</td>\n",
       "      <td>-2.479000e-04</td>\n",
       "      <td>162.513840</td>\n",
       "      <td>0.003520</td>\n",
       "      <td>-0.003520</td>\n",
       "      <td>...</td>\n",
       "      <td>4.467</td>\n",
       "      <td>0.064</td>\n",
       "      <td>-0.096</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.105</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>291.93423</td>\n",
       "      <td>48.141651</td>\n",
       "      <td>15.347</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19.899140</td>\n",
       "      <td>1.490000e-05</td>\n",
       "      <td>-1.490000e-05</td>\n",
       "      <td>175.850252</td>\n",
       "      <td>0.000581</td>\n",
       "      <td>-0.000581</td>\n",
       "      <td>...</td>\n",
       "      <td>4.544</td>\n",
       "      <td>0.044</td>\n",
       "      <td>-0.176</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.233</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>297.00482</td>\n",
       "      <td>48.134129</td>\n",
       "      <td>15.436</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.736952</td>\n",
       "      <td>2.630000e-07</td>\n",
       "      <td>-2.630000e-07</td>\n",
       "      <td>170.307565</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>-0.000115</td>\n",
       "      <td>...</td>\n",
       "      <td>4.564</td>\n",
       "      <td>0.053</td>\n",
       "      <td>-0.168</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.201</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>285.53461</td>\n",
       "      <td>48.285210</td>\n",
       "      <td>15.597</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.525592</td>\n",
       "      <td>3.760000e-06</td>\n",
       "      <td>-3.760000e-06</td>\n",
       "      <td>171.595550</td>\n",
       "      <td>0.001130</td>\n",
       "      <td>-0.001130</td>\n",
       "      <td>...</td>\n",
       "      <td>4.438</td>\n",
       "      <td>0.070</td>\n",
       "      <td>-0.210</td>\n",
       "      <td>1.046</td>\n",
       "      <td>0.334</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>288.75488</td>\n",
       "      <td>48.226200</td>\n",
       "      <td>15.509</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.134435</td>\n",
       "      <td>1.050000e-05</td>\n",
       "      <td>-1.050000e-05</td>\n",
       "      <td>172.979370</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>-0.001900</td>\n",
       "      <td>...</td>\n",
       "      <td>4.486</td>\n",
       "      <td>0.054</td>\n",
       "      <td>-0.229</td>\n",
       "      <td>0.972</td>\n",
       "      <td>0.315</td>\n",
       "      <td>-0.105</td>\n",
       "      <td>296.28613</td>\n",
       "      <td>48.224670</td>\n",
       "      <td>15.714</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   koi_fpflag_nt  koi_fpflag_ss  koi_fpflag_co  koi_fpflag_ec  koi_period  \\\n",
       "0              0              0              0              0   54.418383   \n",
       "1              0              1              0              0   19.899140   \n",
       "2              0              1              0              0    1.736952   \n",
       "3              0              0              0              0    2.525592   \n",
       "4              0              0              0              0    4.134435   \n",
       "\n",
       "   koi_period_err1  koi_period_err2  koi_time0bk  koi_time0bk_err1  \\\n",
       "0     2.479000e-04    -2.479000e-04   162.513840          0.003520   \n",
       "1     1.490000e-05    -1.490000e-05   175.850252          0.000581   \n",
       "2     2.630000e-07    -2.630000e-07   170.307565          0.000115   \n",
       "3     3.760000e-06    -3.760000e-06   171.595550          0.001130   \n",
       "4     1.050000e-05    -1.050000e-05   172.979370          0.001900   \n",
       "\n",
       "   koi_time0bk_err2  ...  koi_slogg  koi_slogg_err1  koi_slogg_err2  koi_srad  \\\n",
       "0         -0.003520  ...      4.467           0.064          -0.096     0.927   \n",
       "1         -0.000581  ...      4.544           0.044          -0.176     0.868   \n",
       "2         -0.000115  ...      4.564           0.053          -0.168     0.791   \n",
       "3         -0.001130  ...      4.438           0.070          -0.210     1.046   \n",
       "4         -0.001900  ...      4.486           0.054          -0.229     0.972   \n",
       "\n",
       "   koi_srad_err1  koi_srad_err2         ra        dec  koi_kepmag  \\\n",
       "0          0.105         -0.061  291.93423  48.141651      15.347   \n",
       "1          0.233         -0.078  297.00482  48.134129      15.436   \n",
       "2          0.201         -0.067  285.53461  48.285210      15.597   \n",
       "3          0.334         -0.133  288.75488  48.226200      15.509   \n",
       "4          0.315         -0.105  296.28613  48.224670      15.714   \n",
       "\n",
       "   koi_disposition_label  \n",
       "0                      1  \n",
       "1                      0  \n",
       "2                      0  \n",
       "3                      1  \n",
       "4                      1  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = {\"FALSE POSITIVE\":0, \"CONFIRMED\": 1, \"CANDIDATE\": 2}\n",
    "\n",
    "df[\"koi_disposition_label\"] = [labels[x] for x in df.koi_disposition]\n",
    "df = df.drop(\"koi_disposition\", axis=1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "koi_disposition_label    1.000000\n",
       "koi_fpflag_ss            0.486481\n",
       "koi_fpflag_co            0.452002\n",
       "koi_fpflag_nt            0.380710\n",
       "koi_fpflag_ec            0.339983\n",
       "koi_steff_err1           0.254084\n",
       "koi_depth                0.244109\n",
       "koi_teq                  0.237782\n",
       "koi_model_snr            0.233840\n",
       "koi_steff_err2           0.232041\n",
       "koi_tce_plnt_num         0.135711\n",
       "koi_duration             0.134811\n",
       "koi_steff                0.133363\n",
       "ra                       0.117899\n",
       "koi_slogg_err2           0.104482\n",
       "koi_slogg                0.101181\n",
       "koi_slogg_err1           0.099996\n",
       "koi_srad_err1            0.077580\n",
       "dec                      0.072855\n",
       "koi_impact               0.067744\n",
       "koi_impact_err1          0.065843\n",
       "koi_kepmag               0.054859\n",
       "koi_srad_err2            0.053862\n",
       "koi_period_err2          0.047197\n",
       "koi_period_err1          0.047197\n",
       "koi_srad                 0.045170\n",
       "koi_prad_err1            0.035515\n",
       "koi_insol_err1           0.031934\n",
       "koi_time0bk_err2         0.029161\n",
       "koi_time0bk_err1         0.029161\n",
       "koi_prad                 0.029047\n",
       "koi_prad_err2            0.025778\n",
       "koi_period               0.023592\n",
       "koi_insol                0.021096\n",
       "koi_depth_err1           0.018775\n",
       "koi_depth_err2           0.018775\n",
       "koi_duration_err1        0.015295\n",
       "koi_duration_err2        0.015295\n",
       "koi_insol_err2           0.015126\n",
       "koi_time0bk              0.009463\n",
       "koi_impact_err2          0.006219\n",
       "Name: koi_disposition_label, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(df.corr(method ='pearson')[\"koi_disposition_label\"]).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Select your features (columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>koi_disposition_label</th>\n",
       "      <th>koi_fpflag_ss</th>\n",
       "      <th>koi_fpflag_co</th>\n",
       "      <th>koi_fpflag_nt</th>\n",
       "      <th>koi_fpflag_ec</th>\n",
       "      <th>koi_steff_err1</th>\n",
       "      <th>koi_depth</th>\n",
       "      <th>koi_teq</th>\n",
       "      <th>koi_model_snr</th>\n",
       "      <th>koi_steff_err2</th>\n",
       "      <th>...</th>\n",
       "      <th>koi_slogg_err1</th>\n",
       "      <th>koi_srad_err1</th>\n",
       "      <th>dec</th>\n",
       "      <th>koi_impact</th>\n",
       "      <th>koi_impact_err1</th>\n",
       "      <th>koi_kepmag</th>\n",
       "      <th>koi_srad_err2</th>\n",
       "      <th>koi_impact_err1</th>\n",
       "      <th>koi_kepmag</th>\n",
       "      <th>koi_srad_err2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>874.8</td>\n",
       "      <td>443</td>\n",
       "      <td>25.8</td>\n",
       "      <td>-81</td>\n",
       "      <td>...</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.105</td>\n",
       "      <td>48.141651</td>\n",
       "      <td>0.586</td>\n",
       "      <td>0.059</td>\n",
       "      <td>15.347</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>0.059</td>\n",
       "      <td>15.347</td>\n",
       "      <td>-0.061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>158</td>\n",
       "      <td>10829.0</td>\n",
       "      <td>638</td>\n",
       "      <td>76.3</td>\n",
       "      <td>-176</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.233</td>\n",
       "      <td>48.134129</td>\n",
       "      <td>0.969</td>\n",
       "      <td>5.126</td>\n",
       "      <td>15.436</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>5.126</td>\n",
       "      <td>15.436</td>\n",
       "      <td>-0.078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>157</td>\n",
       "      <td>8079.2</td>\n",
       "      <td>1395</td>\n",
       "      <td>505.6</td>\n",
       "      <td>-174</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.201</td>\n",
       "      <td>48.285210</td>\n",
       "      <td>1.276</td>\n",
       "      <td>0.115</td>\n",
       "      <td>15.597</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>0.115</td>\n",
       "      <td>15.597</td>\n",
       "      <td>-0.067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>169</td>\n",
       "      <td>603.3</td>\n",
       "      <td>1406</td>\n",
       "      <td>40.9</td>\n",
       "      <td>-211</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.334</td>\n",
       "      <td>48.226200</td>\n",
       "      <td>0.701</td>\n",
       "      <td>0.235</td>\n",
       "      <td>15.509</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>0.235</td>\n",
       "      <td>15.509</td>\n",
       "      <td>-0.133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>189</td>\n",
       "      <td>686.0</td>\n",
       "      <td>1160</td>\n",
       "      <td>40.2</td>\n",
       "      <td>-232</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.315</td>\n",
       "      <td>48.224670</td>\n",
       "      <td>0.762</td>\n",
       "      <td>0.139</td>\n",
       "      <td>15.714</td>\n",
       "      <td>-0.105</td>\n",
       "      <td>0.139</td>\n",
       "      <td>15.714</td>\n",
       "      <td>-0.105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   koi_disposition_label  koi_fpflag_ss  koi_fpflag_co  koi_fpflag_nt  \\\n",
       "0                      1              0              0              0   \n",
       "1                      0              1              0              0   \n",
       "2                      0              1              0              0   \n",
       "3                      1              0              0              0   \n",
       "4                      1              0              0              0   \n",
       "\n",
       "   koi_fpflag_ec  koi_steff_err1  koi_depth  koi_teq  koi_model_snr  \\\n",
       "0              0              81      874.8      443           25.8   \n",
       "1              0             158    10829.0      638           76.3   \n",
       "2              0             157     8079.2     1395          505.6   \n",
       "3              0             169      603.3     1406           40.9   \n",
       "4              0             189      686.0     1160           40.2   \n",
       "\n",
       "   koi_steff_err2  ...  koi_slogg_err1  koi_srad_err1        dec  koi_impact  \\\n",
       "0             -81  ...           0.064          0.105  48.141651       0.586   \n",
       "1            -176  ...           0.044          0.233  48.134129       0.969   \n",
       "2            -174  ...           0.053          0.201  48.285210       1.276   \n",
       "3            -211  ...           0.070          0.334  48.226200       0.701   \n",
       "4            -232  ...           0.054          0.315  48.224670       0.762   \n",
       "\n",
       "   koi_impact_err1  koi_kepmag  koi_srad_err2  koi_impact_err1  koi_kepmag  \\\n",
       "0            0.059      15.347         -0.061            0.059      15.347   \n",
       "1            5.126      15.436         -0.078            5.126      15.436   \n",
       "2            0.115      15.597         -0.067            0.115      15.597   \n",
       "3            0.235      15.509         -0.133            0.235      15.509   \n",
       "4            0.139      15.714         -0.105            0.139      15.714   \n",
       "\n",
       "   koi_srad_err2  \n",
       "0         -0.061  \n",
       "1         -0.078  \n",
       "2         -0.067  \n",
       "3         -0.133  \n",
       "4         -0.105  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set features. This will also be used as your x values.\n",
    "selectedFeatures = df[[\n",
    "    'koi_disposition_label',\n",
    "    'koi_fpflag_ss',\n",
    "    'koi_fpflag_co',\n",
    "    'koi_fpflag_nt',\n",
    "    'koi_fpflag_ec',\n",
    "    'koi_steff_err1',\n",
    "    'koi_depth',\n",
    "    'koi_teq',\n",
    "    'koi_model_snr',\n",
    "    'koi_steff_err2',\n",
    "    'koi_tce_plnt_num',\n",
    "    'koi_duration',\n",
    "    'koi_steff',\n",
    "    'ra',\n",
    "    'koi_slogg_err2',\n",
    "    'koi_slogg',\n",
    "    'koi_slogg_err1',\n",
    "    'koi_srad_err1',\n",
    "    'dec',\n",
    "    'koi_impact',\n",
    "    'koi_impact_err1',\n",
    "    'koi_kepmag',\n",
    "    'koi_srad_err2',\n",
    "    'koi_impact_err1',\n",
    "    'koi_kepmag',\n",
    "    'koi_srad_err2'\n",
    "]]\n",
    "selectedFeatures.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Train Test Split\n",
    "\n",
    "Use `koi_disposition` for the y values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = selectedFeatures\n",
    "y = df[\"koi_disposition_label\"].values.reshape(-1, 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>koi_disposition_label</th>\n",
       "      <th>koi_fpflag_ss</th>\n",
       "      <th>koi_fpflag_co</th>\n",
       "      <th>koi_fpflag_nt</th>\n",
       "      <th>koi_fpflag_ec</th>\n",
       "      <th>koi_steff_err1</th>\n",
       "      <th>koi_depth</th>\n",
       "      <th>koi_teq</th>\n",
       "      <th>koi_model_snr</th>\n",
       "      <th>koi_steff_err2</th>\n",
       "      <th>...</th>\n",
       "      <th>koi_slogg_err1</th>\n",
       "      <th>koi_srad_err1</th>\n",
       "      <th>dec</th>\n",
       "      <th>koi_impact</th>\n",
       "      <th>koi_impact_err1</th>\n",
       "      <th>koi_kepmag</th>\n",
       "      <th>koi_srad_err2</th>\n",
       "      <th>koi_impact_err1</th>\n",
       "      <th>koi_kepmag</th>\n",
       "      <th>koi_srad_err2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3563</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>102.9</td>\n",
       "      <td>899</td>\n",
       "      <td>11.7</td>\n",
       "      <td>-133</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.181</td>\n",
       "      <td>44.737061</td>\n",
       "      <td>1.0170</td>\n",
       "      <td>0.0470</td>\n",
       "      <td>13.204</td>\n",
       "      <td>-0.097</td>\n",
       "      <td>0.0470</td>\n",
       "      <td>13.204</td>\n",
       "      <td>-0.097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4099</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>593.3</td>\n",
       "      <td>491</td>\n",
       "      <td>18.0</td>\n",
       "      <td>-144</td>\n",
       "      <td>...</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.056</td>\n",
       "      <td>42.576248</td>\n",
       "      <td>0.7090</td>\n",
       "      <td>0.0230</td>\n",
       "      <td>15.514</td>\n",
       "      <td>-0.076</td>\n",
       "      <td>0.0230</td>\n",
       "      <td>15.514</td>\n",
       "      <td>-0.076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5460</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>126</td>\n",
       "      <td>47337.0</td>\n",
       "      <td>1276</td>\n",
       "      <td>476.0</td>\n",
       "      <td>-140</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.054</td>\n",
       "      <td>49.310040</td>\n",
       "      <td>0.2620</td>\n",
       "      <td>0.2740</td>\n",
       "      <td>15.414</td>\n",
       "      <td>-0.060</td>\n",
       "      <td>0.2740</td>\n",
       "      <td>15.414</td>\n",
       "      <td>-0.060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1091</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "      <td>584.8</td>\n",
       "      <td>300</td>\n",
       "      <td>34.7</td>\n",
       "      <td>-112</td>\n",
       "      <td>...</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.135</td>\n",
       "      <td>48.131390</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.4170</td>\n",
       "      <td>13.328</td>\n",
       "      <td>-0.083</td>\n",
       "      <td>0.4170</td>\n",
       "      <td>13.328</td>\n",
       "      <td>-0.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5999</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>164</td>\n",
       "      <td>193.6</td>\n",
       "      <td>568</td>\n",
       "      <td>8.7</td>\n",
       "      <td>-233</td>\n",
       "      <td>...</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.905</td>\n",
       "      <td>39.812420</td>\n",
       "      <td>0.2136</td>\n",
       "      <td>0.2282</td>\n",
       "      <td>12.964</td>\n",
       "      <td>-0.383</td>\n",
       "      <td>0.2282</td>\n",
       "      <td>12.964</td>\n",
       "      <td>-0.383</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      koi_disposition_label  koi_fpflag_ss  koi_fpflag_co  koi_fpflag_nt  \\\n",
       "3563                      2              0              0              0   \n",
       "4099                      1              0              0              0   \n",
       "5460                      2              0              0              0   \n",
       "1091                      1              0              0              0   \n",
       "5999                      2              0              0              0   \n",
       "\n",
       "      koi_fpflag_ec  koi_steff_err1  koi_depth  koi_teq  koi_model_snr  \\\n",
       "3563              0             120      102.9      899           11.7   \n",
       "4099              0             144      593.3      491           18.0   \n",
       "5460              0             126    47337.0     1276          476.0   \n",
       "1091              0             101      584.8      300           34.7   \n",
       "5999              0             164      193.6      568            8.7   \n",
       "\n",
       "      koi_steff_err2  ...  koi_slogg_err1  koi_srad_err1        dec  \\\n",
       "3563            -133  ...           0.066          0.181  44.737061   \n",
       "4099            -144  ...           0.078          0.056  42.576248   \n",
       "5460            -140  ...           0.054          0.054  49.310040   \n",
       "1091            -112  ...           0.072          0.135  48.131390   \n",
       "5999            -233  ...           0.164          0.905  39.812420   \n",
       "\n",
       "      koi_impact  koi_impact_err1  koi_kepmag  koi_srad_err2  koi_impact_err1  \\\n",
       "3563      1.0170           0.0470      13.204         -0.097           0.0470   \n",
       "4099      0.7090           0.0230      15.514         -0.076           0.0230   \n",
       "5460      0.2620           0.2740      15.414         -0.060           0.2740   \n",
       "1091      0.0010           0.4170      13.328         -0.083           0.4170   \n",
       "5999      0.2136           0.2282      12.964         -0.383           0.2282   \n",
       "\n",
       "      koi_kepmag  koi_srad_err2  \n",
       "3563      13.204         -0.097  \n",
       "4099      15.514         -0.076  \n",
       "5460      15.414         -0.060  \n",
       "1091      13.328         -0.083  \n",
       "5999      12.964         -0.383  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "\n",
    "Scale the data using the MinMaxScaler and perform some feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale your data\n",
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kylec\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\kylec\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\kylec\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "model = classifier.fit(X_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.6135800114438299\n",
      "Testing Data Score: 0.6161327231121282\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Data Score: {model.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {model.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning\n",
    "\n",
    "Use `GridSearchCV` to tune the model's parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the GridSearchCV model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C': [1, 5, 10],\n",
    "              'penalty': [\"l1\", \"l2\"]}\n",
    "grid = GridSearchCV(model, param_grid, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\Users\\kylec\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kylec\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\kylec\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\kylec\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "C:\\Users\\kylec\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[CV] C=1, penalty=l1 .................................................\n",
      "[CV] ....................... C=1, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=1, penalty=l1 .................................................\n",
      "[CV] ....................... C=1, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=1, penalty=l1 .................................................\n",
      "[CV] ....................... C=1, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=1, penalty=l1 .................................................\n",
      "[CV] ....................... C=1, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=1, penalty=l1 .................................................\n",
      "[CV] ....................... C=1, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=1, penalty=l2 .................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kylec\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\kylec\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... C=1, penalty=l2, score=0.615, total=   0.2s\n",
      "[CV] C=1, penalty=l2 .................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kylec\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\kylec\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\kylec\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\kylec\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... C=1, penalty=l2, score=0.629, total=   0.3s\n",
      "[CV] C=1, penalty=l2 .................................................\n",
      "[CV] ..................... C=1, penalty=l2, score=0.596, total=   0.2s\n",
      "[CV] C=1, penalty=l2 .................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kylec\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\kylec\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... C=1, penalty=l2, score=0.610, total=   0.2s\n",
      "[CV] C=1, penalty=l2 .................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kylec\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\kylec\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kylec\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\kylec\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\kylec\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\kylec\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\kylec\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... C=1, penalty=l2, score=0.609, total=   0.2s\n",
      "[CV] C=5, penalty=l1 .................................................\n",
      "[CV] ....................... C=5, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=5, penalty=l1 .................................................\n",
      "[CV] ....................... C=5, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=5, penalty=l1 .................................................\n",
      "[CV] ....................... C=5, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=5, penalty=l1 .................................................\n",
      "[CV] ....................... C=5, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=5, penalty=l1 .................................................\n",
      "[CV] ....................... C=5, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=5, penalty=l2 .................................................\n",
      "[CV] ..................... C=5, penalty=l2, score=0.626, total=   0.2s\n",
      "[CV] C=5, penalty=l2 .................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kylec\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\kylec\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\kylec\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... C=5, penalty=l2, score=0.622, total=   0.2s\n",
      "[CV] C=5, penalty=l2 .................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kylec\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\kylec\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\kylec\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\kylec\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... C=5, penalty=l2, score=0.596, total=   0.2s\n",
      "[CV] C=5, penalty=l2 .................................................\n",
      "[CV] ..................... C=5, penalty=l2, score=0.610, total=   0.2s\n",
      "[CV] C=5, penalty=l2 .................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kylec\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\kylec\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kylec\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\kylec\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\kylec\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\kylec\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... C=5, penalty=l2, score=0.603, total=   0.2s\n",
      "[CV] C=10, penalty=l1 ................................................\n",
      "[CV] ...................... C=10, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=10, penalty=l1 ................................................\n",
      "[CV] ...................... C=10, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=10, penalty=l1 ................................................\n",
      "[CV] ...................... C=10, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=10, penalty=l1 ................................................\n",
      "[CV] ...................... C=10, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=10, penalty=l1 ................................................\n",
      "[CV] ...................... C=10, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=10, penalty=l2 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kylec\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\kylec\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\kylec\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\kylec\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... C=10, penalty=l2, score=0.629, total=   0.2s\n",
      "[CV] C=10, penalty=l2 ................................................\n",
      "[CV] .................... C=10, penalty=l2, score=0.626, total=   0.2s\n",
      "[CV] C=10, penalty=l2 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kylec\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\kylec\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... C=10, penalty=l2, score=0.596, total=   0.2s\n",
      "[CV] C=10, penalty=l2 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kylec\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\kylec\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\kylec\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    3.0s finished\n",
      "C:\\Users\\kylec\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... C=10, penalty=l2, score=0.611, total=   0.2s\n",
      "[CV] C=10, penalty=l2 ................................................\n",
      "[CV] .................... C=10, penalty=l2, score=0.607, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kylec\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=LogisticRegression(),\n",
       "             param_grid={'C': [1, 5, 10], 'penalty': ['l1', 'l2']}, verbose=3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model with GridSearch\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'penalty': 'l2'}\n",
      "0.61376883837024\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kylec\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\kylec\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Analysis:\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       909\n",
      "           1       1.00      1.00      1.00       435\n",
      "           2       1.00      1.00      1.00       404\n",
      "\n",
      "    accuracy                           1.00      1748\n",
      "   macro avg       1.00      1.00      1.00      1748\n",
      "weighted avg       1.00      1.00      1.00      1748\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[909   0   0]\n",
      " [  0 435   0]\n",
      " [  0   0 404]]\n",
      "\n",
      "ROC Curve:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lrc = LogisticRegression() #init\n",
    "lrc.fit(X_train_scaled, y_train) #fit\n",
    "preds = lrc.predict(X_test_scaled) #predict\n",
    "proba_preds = lrc.predict_proba(X_test_scaled) #predict\n",
    "\n",
    "print(\"Logistic Regression Analysis:\")\n",
    "print(\"Classification Report:\")\n",
    "print()\n",
    "print(classification_report(y_test, preds)) #evaluate\n",
    "print()\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, preds)) #evaluate\n",
    "\n",
    "#plot confusion matrix\n",
    "# fig, ax = plt.subplots(figsize=(5, 5))\n",
    "# plot_confusion_matrix(y_test, preds, normalize=True, ax=ax) #plot\n",
    "# plt.show()\n",
    "print()\n",
    "print(\"ROC Curve:\")\n",
    "plot_roc(y_test, proba_preds) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kyleLogRegModel.sav']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save your model by updating \"your_name\" with your name\n",
    "# and \"your_model\" with your model variable\n",
    "# be sure to turn this in to BCS\n",
    "# if joblib fails to import, try running the command to install in terminal/git-bash\n",
    "import joblib\n",
    "filename = 'kyleLogRegModel.sav'\n",
    "joblib.dump(model, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "dev"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "nteract": {
   "version": "0.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
